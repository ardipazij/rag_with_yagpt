{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "e416cf2d799d4cd692e98f804f6effed": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c798107148054e15acc00d88d4b4bb7e",
       "IPY_MODEL_60bc2d7db0bf46ef83dc8f412df92ea8",
       "IPY_MODEL_b1a7aa6694a44a0da976020bdceeac50"
      ],
      "layout": "IPY_MODEL_702106b506cb4165aa5c3d43ff00abec"
     }
    },
    "c798107148054e15acc00d88d4b4bb7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2d5c0cf4240442d8e3ab4a35fa1155c",
      "placeholder": "​",
      "style": "IPY_MODEL_3b1a89eabccd4a29a1db2e24f3946efa",
      "value": "Batches: 100%"
     }
    },
    "60bc2d7db0bf46ef83dc8f412df92ea8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_313a299ec1c74cb4971043ad2865d0e9",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0a971983383c40f4b7a91977bae9504e",
      "value": 1
     }
    },
    "b1a7aa6694a44a0da976020bdceeac50": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f9c66addea04d81895d7d51874bf771",
      "placeholder": "​",
      "style": "IPY_MODEL_0921835bdedb4de5bf6e86404f2497a7",
      "value": " 1/1 [00:00&lt;00:00,  6.33it/s]"
     }
    },
    "702106b506cb4165aa5c3d43ff00abec": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2d5c0cf4240442d8e3ab4a35fa1155c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b1a89eabccd4a29a1db2e24f3946efa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "313a299ec1c74cb4971043ad2865d0e9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a971983383c40f4b7a91977bae9504e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8f9c66addea04d81895d7d51874bf771": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0921835bdedb4de5bf6e86404f2497a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install faiss-cpu sentence-transformers yandexcloud grpcio yandex-cloud-ml-sdk\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lmjG_WPYzt6D",
    "outputId": "ec68d72b-0781-4747-f69d-a42961dc5bcf"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
      "Requirement already satisfied: yandexcloud in /usr/local/lib/python3.11/dist-packages (0.337.0)\n",
      "Requirement already satisfied: grpcio in /usr/local/lib/python3.11/dist-packages (1.71.0)\n",
      "Collecting yandex-cloud-ml-sdk\n",
      "  Downloading yandex_cloud_ml_sdk-0.7.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.50.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: cryptography>=44.0.0 in /usr/local/lib/python3.11/dist-packages (from yandexcloud) (44.0.2)\n",
      "Requirement already satisfied: protobuf<6,>=5.29.1 in /usr/local/lib/python3.11/dist-packages (from yandexcloud) (5.29.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.66.0 in /usr/local/lib/python3.11/dist-packages (from yandexcloud) (1.69.2)\n",
      "Requirement already satisfied: pyjwt<3,>=2.10.1 in /usr/local/lib/python3.11/dist-packages (from yandexcloud) (2.10.1)\n",
      "Requirement already satisfied: requests<3,>=2.32.3 in /usr/local/lib/python3.11/dist-packages (from yandexcloud) (2.32.3)\n",
      "Requirement already satisfied: six<2,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from yandexcloud) (1.17.0)\n",
      "Requirement already satisfied: grpcio-tools>=1.68.1 in /usr/local/lib/python3.11/dist-packages (from yandexcloud) (1.71.0)\n",
      "Requirement already satisfied: deprecated>=1.2.18 in /usr/local/lib/python3.11/dist-packages (from yandexcloud) (1.2.18)\n",
      "Collecting get-annotations (from yandex-cloud-ml-sdk)\n",
      "  Downloading get_annotations-0.1.2-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.27 in /usr/local/lib/python3.11/dist-packages (from yandex-cloud-ml-sdk) (0.28.1)\n",
      "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.11/dist-packages (from yandex-cloud-ml-sdk) (4.13.0)\n",
      "Collecting aiofiles>=24.1.0 (from yandex-cloud-ml-sdk)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=44.0.0->yandexcloud) (1.17.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.18->yandexcloud) (1.17.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from grpcio-tools>=1.68.1->yandexcloud) (75.2.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.27->yandex-cloud-ml-sdk) (4.9.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.27->yandex-cloud-ml-sdk) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.27->yandex-cloud-ml-sdk) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.27->yandex-cloud-ml-sdk) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.27->yandex-cloud-ml-sdk) (0.14.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.32.3->yandexcloud) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.32.3->yandexcloud) (2.3.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=44.0.0->yandexcloud) (2.22)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.27->yandex-cloud-ml-sdk) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Downloading yandex_cloud_ml_sdk-0.7.0-py3-none-any.whl (127 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m127.4/127.4 kB\u001B[0m \u001B[31m3.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading get_annotations-0.1.2-py3-none-any.whl (4.5 kB)\n",
      "Installing collected packages: get-annotations, aiofiles, yandex-cloud-ml-sdk\n",
      "Successfully installed aiofiles-24.1.0 get-annotations-0.1.2 yandex-cloud-ml-sdk-0.7.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from yandex_cloud_ml_sdk import YCloudML\n",
    "from typing import Dict, List, Optional, Any\n",
    "import uuid\n",
    "import datetime\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "import json\n",
    "import os\n",
    "\n",
    "class YandexGPTClient:\n",
    "    def __init__(self, api_key: str, folder_id: str):\n",
    "        self.sdk = YCloudML(\n",
    "            folder_id=folder_id,\n",
    "            auth=api_key\n",
    "        )\n",
    "        self.model = self.sdk.models.completions(\"yandexgpt\", model_version=\"rc\")\n",
    "        self.model = self.model.configure(temperature=0.6, max_tokens=2000)\n",
    "\n",
    "    def generate_response(self, prompt: str) -> str:\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"text\": \"Ты - помощник по умному термостату. Отвечай на вопросы кратко и по делу.\"},\n",
    "            {\"role\": \"user\", \"text\": prompt}\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            result = self.model.run(messages)\n",
    "            if hasattr(result[0], 'text'):\n",
    "                return result[0].text\n",
    "            elif hasattr(result[0], 'message') and hasattr(result[0].message, 'text'):\n",
    "                return result[0].message.text\n",
    "            elif hasattr(result[0], 'alternatives') and len(result[0].alternatives) > 0:\n",
    "                return result[0].alternatives[0].message.text\n",
    "            else:\n",
    "                return \"Не удалось обработать ответ от модели.\"\n",
    "        except Exception as e:\n",
    "            return f\"Ошибка при генерации ответа: {str(e)}\"\n",
    "\n",
    "class FAISSVectorStore:\n",
    "    def __init__(self, dimension: int = 384):\n",
    "        self.dimension = dimension\n",
    "        self.index = faiss.IndexFlatL2(dimension)\n",
    "        self.documents = []\n",
    "        self.encoder = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "    def add_documents(self, documents: List[Dict[str, Any]]):\n",
    "        texts = [doc['text'] for doc in documents]\n",
    "        embeddings = self.encoder.encode(texts, show_progress_bar=True)\n",
    "        self.index.add(np.array(embeddings).astype('float32'))\n",
    "        self.documents.extend(documents)\n",
    "\n",
    "    def search(self, query: str, k: int = 3) -> List[Dict[str, Any]]:\n",
    "        query_embedding = self.encoder.encode([query])\n",
    "        distances, indices = self.index.search(np.array(query_embedding).astype('float32'), k)\n",
    "        return [self.documents[i] for i in indices[0]]\n",
    "\n",
    "class DialogManager:\n",
    "    def __init__(self, vector_store: FAISSVectorStore, llm_client: YandexGPTClient):\n",
    "        self.vector_store = vector_store\n",
    "        self.llm_client = llm_client\n",
    "        self.active_dialogs = {}\n",
    "        self.dialog_templates = self._load_dialog_templates()\n",
    "        self.tickets_dir = \"support_tickets\"\n",
    "        if not os.path.exists(self.tickets_dir):\n",
    "            os.makedirs(self.tickets_dir)\n",
    "\n",
    "    def _load_dialog_templates(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"thermostat_diagnosis\": {\n",
    "                \"steps\": [\n",
    "                    {\n",
    "                        \"id\": \"welcome\",\n",
    "                        \"prompt\": \"Привет! Я помогу тебе с настройкой термостата. Какую проблему ты наблюдаешь?\",\n",
    "                        \"variable\": None,\n",
    "                        \"next_step\": \"current_temp\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"id\": \"current_temp\",\n",
    "                        \"prompt\": \"Какая температура сейчас в комнате?\",\n",
    "                        \"variable\": \"current_temp\",\n",
    "                        \"next_step\": \"desired_temp\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"id\": \"desired_temp\",\n",
    "                        \"prompt\": \"Какая температура должна быть в комнате?\",\n",
    "                        \"variable\": \"desired_temp\",\n",
    "                        \"next_step\": \"time_of_day\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"id\": \"time_of_day\",\n",
    "                        \"prompt\": \"Когда это произошло? Утром, днем или вечером?\",\n",
    "                        \"variable\": \"time_of_day\",\n",
    "                        \"next_step\": {\n",
    "                            \"condition\": \"check_duration\",\n",
    "                            \"function\": self._check_duration_condition\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"id\": \"create_ticket\",\n",
    "                        \"prompt\": \"Хотите создать заявку на техподдержку?\",\n",
    "                        \"variable\": \"create_ticket\",\n",
    "                        \"next_step\": {\n",
    "                            \"condition\": \"user_choice\",\n",
    "                            \"options\": {\n",
    "                                \"Да\": \"ticket_created\",\n",
    "                                \"Нет\": \"end_conversation\"\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"id\": \"wait_hour\",\n",
    "                        \"prompt\": \"Подождите в течение часа, если проблема продолжает наблюдаться - снова обратитесь ко мне.\",\n",
    "                        \"next_step\": \"end_conversation\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"id\": \"ticket_created\",\n",
    "                        \"prompt\": \"Заявка создана. Техподдержка свяжется с вами в ближайшее время.\",\n",
    "                        \"next_step\": \"end_conversation\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"id\": \"end_conversation\",\n",
    "                        \"prompt\": \"Все готово! Если потребуется дополнительная помощь, обращайтесь.\",\n",
    "                        \"next_step\": None\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def _check_duration_condition(self, dialog_state: Dict[str, Any]) -> str:\n",
    "        return \"create_ticket\"\n",
    "\n",
    "    def start_new_dialog(self, dialog_type: str) -> str:\n",
    "        dialog_id = str(uuid.uuid4())\n",
    "        self.active_dialogs[dialog_id] = {\n",
    "            \"type\": dialog_type,\n",
    "            \"current_step\": \"welcome\",\n",
    "            \"variables\": {},\n",
    "            \"history\": [],\n",
    "            \"start_time\": datetime.datetime.now(),\n",
    "            \"template\": self.dialog_templates.get(dialog_type)\n",
    "        }\n",
    "        return dialog_id\n",
    "\n",
    "    def _save_support_ticket(self, ticket_info: Dict[str, Any]) -> str:\n",
    "        \"\"\"Сохраняет информацию о заявке в файл\"\"\"\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        ticket_id = f\"ticket_{timestamp}\"\n",
    "\n",
    "        dialog_history = []\n",
    "        for entry in ticket_info.get(\"dialog_history\", []):\n",
    "            dialog_history.append({\n",
    "                \"step\": entry[\"step\"],\n",
    "                \"user_input\": entry[\"user_input\"],\n",
    "                \"timestamp\": entry[\"timestamp\"].isoformat() if isinstance(entry[\"timestamp\"], datetime.datetime) else entry[\"timestamp\"]\n",
    "            })\n",
    "\n",
    "        ticket_data = {\n",
    "            \"ticket_id\": ticket_id,\n",
    "            \"status\": \"new\",\n",
    "            \"created_at\": datetime.datetime.now().isoformat(),\n",
    "            \"problem_details\": {\n",
    "                \"current_temp\": ticket_info.get(\"current_temp\"),\n",
    "                \"desired_temp\": ticket_info.get(\"desired_temp\"),\n",
    "                \"time_of_day\": ticket_info.get(\"time_of_day\"),\n",
    "                \"duration\": \"более часа\",\n",
    "            },\n",
    "            \"dialog_history\": dialog_history,\n",
    "            \"device_info\": {\n",
    "                \"type\": \"smart_thermostat\",\n",
    "                \"error_state\": ticket_info.get(\"error_state\", False)\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # сохраняем в JSON файл\n",
    "        filename = os.path.join(self.tickets_dir, f\"{ticket_id}.json\")\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(ticket_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        return ticket_id\n",
    "\n",
    "    def process_user_input(self, dialog_id: str, user_input: str) -> str:\n",
    "        if dialog_id not in self.active_dialogs:\n",
    "            return \"Диалог не найден. Пожалуйста, начните новый диалог.\"\n",
    "\n",
    "        # проверка на некорректный ввод\n",
    "        if not user_input or any(word in user_input.lower() for word in [\"хуй\", \"fuck\", \"блять\"]):\n",
    "            return \"Пожалуйста, давайте общаться вежливо. Я здесь, чтобы помочь вам с термостатом.\"\n",
    "\n",
    "        dialog_state = self.active_dialogs[dialog_id]\n",
    "        current_step_id = dialog_state[\"current_step\"]\n",
    "        variables = dialog_state[\"variables\"]\n",
    "\n",
    "        # сохраняем историю\n",
    "        dialog_state[\"history\"].append({\n",
    "            \"step\": current_step_id,\n",
    "            \"user_input\": user_input,\n",
    "            \"timestamp\": datetime.datetime.now()\n",
    "        })\n",
    "\n",
    "        def extract_temperature(text: str) -> Optional[float]:\n",
    "            try:\n",
    "                if \"error\" in text.lower() or \"нет температуры\" in text.lower():\n",
    "                    return None\n",
    "\n",
    "                text = text.lower()\n",
    "                text = text.replace(\"градуса\", \"\").replace(\"°c\", \"\")\n",
    "                text = text.replace(\"температура\", \"\").replace(\"-\", \"\")\n",
    "                text = text.replace(\"текущая\", \"\").replace(\"желаемая\", \"\")\n",
    "                text = text.strip()\n",
    "                temp = float(text)\n",
    "\n",
    "                # проверка на реалистичность температуры\n",
    "                if temp > 100:  # явно нереальная температура\n",
    "                    return None\n",
    "                return temp\n",
    "            except ValueError:\n",
    "                return None\n",
    "\n",
    "        # Обработка шагов диалога\n",
    "        if current_step_id == \"welcome\":\n",
    "            dialog_state[\"current_step\"] = \"current_temp\"\n",
    "            return (\"Какая температура сейчас в комнате? \\n\"\n",
    "                    \"Если термостат показывает ошибку, пожалуйста, введите примерную температуру в помещении.\")\n",
    "\n",
    "        elif current_step_id == \"current_temp\":\n",
    "            temp = extract_temperature(user_input)\n",
    "            if temp is not None and 10 <= temp <= 35:\n",
    "                variables[\"current_temp\"] = temp\n",
    "                dialog_state[\"current_step\"] = \"desired_temp\"\n",
    "                return \"Какая температура должна быть в комнате?\"\n",
    "            else:\n",
    "                return (\"Пожалуйста, введите температуру числом от 10 до 35 градусов.\\n\"\n",
    "                       \"Например: 22 или 23.5\")\n",
    "\n",
    "        elif current_step_id == \"desired_temp\":\n",
    "            temp = extract_temperature(user_input)\n",
    "            if temp is not None and 10 <= temp <= 35:\n",
    "                variables[\"desired_temp\"] = temp\n",
    "                dialog_state[\"current_step\"] = \"time_of_day\"\n",
    "                return \"Когда это произошло? Утром, днем или вечером?\"\n",
    "            else:\n",
    "                return (\"Пожалуйста, введите желаемую температуру числом от 10 до 35 градусов.\\n\"\n",
    "                       \"Например: 22 или 23.5\")\n",
    "\n",
    "        elif current_step_id == \"time_of_day\":\n",
    "            valid_times = {\"утром\": \"утром\", \"днем\": \"днем\", \"вечером\": \"вечером\",\n",
    "                          \"утро\": \"утром\", \"день\": \"днем\", \"вечер\": \"вечером\",\n",
    "                          \"сейчас\": \"сейчас\"}\n",
    "            user_time = user_input.lower()\n",
    "\n",
    "            # Определяем время суток для \"сейчас\"\n",
    "            if user_time == \"сейчас\":\n",
    "                hour = datetime.datetime.now().hour\n",
    "                if 5 <= hour < 12:\n",
    "                    user_time = \"утром\"\n",
    "                elif 12 <= hour < 18:\n",
    "                    user_time = \"днем\"\n",
    "                else:\n",
    "                    user_time = \"вечером\"\n",
    "\n",
    "            for time_key, time_value in valid_times.items():\n",
    "                if time_key in user_time:\n",
    "                    variables[\"time_of_day\"] = time_value\n",
    "                    dialog_state[\"current_step\"] = \"duration_check\"\n",
    "                    return \"Проблема наблюдается более часа?\"\n",
    "            return (\"Пожалуйста, укажите время суток: утром, днем или вечером\\n\"\n",
    "                   \"Например: утром или днем\")\n",
    "\n",
    "        elif current_step_id == \"duration_check\":\n",
    "            positive_answers = [\"да\", \"yes\", \"более\", \"больше\"]\n",
    "            negative_answers = [\"нет\", \"no\", \"менее\", \"меньше\"]\n",
    "\n",
    "            user_answer = user_input.lower()\n",
    "            if any(ans in user_answer for ans in positive_answers):\n",
    "                dialog_state[\"current_step\"] = \"create_ticket\"\n",
    "                return \"Хотите создать заявку на техподдержку?\"\n",
    "            elif any(ans in user_answer for ans in negative_answers):\n",
    "                dialog_state[\"current_step\"] = \"wait_hour\"\n",
    "                return (\"Подождите в течение часа, если проблема продолжает наблюдаться - \"\n",
    "                       \"снова обратитесь ко мне, и мы создадим заявку в техподдержку.\")\n",
    "            else:\n",
    "                return \"Пожалуйста, ответьте да или нет\"\n",
    "\n",
    "        elif current_step_id == \"wait_hour\":\n",
    "            # Если пользователь пишет, что проблема осталась\n",
    "            if \"проблема\" in user_input.lower() and (\"осталась\" in user_input.lower() or \"продолжается\" in user_input.lower()):\n",
    "                dialog_state[\"current_step\"] = \"create_ticket\"\n",
    "                return \"Хотите создать заявку на техподдержку?\"\n",
    "            dialog_state[\"current_step\"] = \"end_conversation\"\n",
    "            return \"Все готово! Если проблема останется, обратитесь снова, и мы создадим заявку в техподдержку.\"\n",
    "\n",
    "        elif current_step_id == \"create_ticket\":\n",
    "            positive_answers = [\"да\", \"yes\", \"конечно\", \"хочу\"]\n",
    "            if any(ans in user_input.lower() for ans in positive_answers):\n",
    "                # оформление тикета\n",
    "                ticket_info = {\n",
    "                    \"current_temp\": variables.get(\"current_temp\"),\n",
    "                    \"desired_temp\": variables.get(\"desired_temp\"),\n",
    "                    \"time_of_day\": variables.get(\"time_of_day\"),\n",
    "                    \"timestamp\": datetime.datetime.now().isoformat(),\n",
    "                    \"dialog_history\": dialog_state[\"history\"],\n",
    "                    \"error_state\": any(\"error\" in str(h.get(\"user_input\")).lower()\n",
    "                                     for h in dialog_state[\"history\"])\n",
    "                }\n",
    "\n",
    "                # сохранение тикета\n",
    "                ticket_id = self._save_support_ticket(ticket_info)\n",
    "                variables[\"ticket_info\"] = ticket_info\n",
    "                variables[\"ticket_id\"] = ticket_id\n",
    "\n",
    "                dialog_state[\"current_step\"] = \"ticket_created\"\n",
    "                return (f\"Заявка #{ticket_id} создана.\\n\"\n",
    "                       f\"Текущая температура: {variables.get('current_temp')}°C\\n\"\n",
    "                       f\"Желаемая температура: {variables.get('desired_temp')}°C\\n\"\n",
    "                       f\"Время возникновения: {variables.get('time_of_day')}\\n\"\n",
    "                       \"Техподдержка свяжется с вами в ближайшее время.\")\n",
    "            else:\n",
    "                dialog_state[\"current_step\"] = \"end_conversation\"\n",
    "                return \"Хорошо. Если потребуется помощь - обращайтесь.\"\n",
    "\n",
    "        elif current_step_id in [\"ticket_created\", \"end_conversation\"]:\n",
    "            # затычка для непонятливого пользователя\n",
    "            if \"проблема\" in user_input.lower():\n",
    "                return \"Чтобы начать новую диагностику, напишите 'начать'\"\n",
    "            return \"Диалог завершен. Чтобы начать новую диагностику, напишите 'начать'\"\n",
    "\n",
    "        return \"Извините, произошла ошибка. Чтобы начать заново, напишите 'начать'\"\n",
    "\n",
    "vector_store = FAISSVectorStore()\n",
    "llm_client = YandexGPTClient(api_key=\"апишечка\", folder_id=\"папочка\")\n",
    "dialog_manager = DialogManager(vector_store, llm_client)\n",
    "\n",
    "documents = [\n",
    "    {\"text\": \"Умный термостат не поддерживает температуру. Возможные причины: неисправность датчика, проблемы с питанием.\"},\n",
    "    {\"text\": \"Для создания заявки на техподдержку термостата необходимо указать текущую и желаемую температуру.\"},\n",
    "    {\"text\": \"Среднее время реакции техподдержки по заявкам - 1 час в рабочее время.\"}\n",
    "]\n",
    "vector_store.add_documents(documents)\n",
    "\n",
    "dialog_id = dialog_manager.start_new_dialog(\"thermostat_diagnosis\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "e416cf2d799d4cd692e98f804f6effed",
      "c798107148054e15acc00d88d4b4bb7e",
      "60bc2d7db0bf46ef83dc8f412df92ea8",
      "b1a7aa6694a44a0da976020bdceeac50",
      "702106b506cb4165aa5c3d43ff00abec",
      "c2d5c0cf4240442d8e3ab4a35fa1155c",
      "3b1a89eabccd4a29a1db2e24f3946efa",
      "313a299ec1c74cb4971043ad2865d0e9",
      "0a971983383c40f4b7a91977bae9504e",
      "8f9c66addea04d81895d7d51874bf771",
      "0921835bdedb4de5bf6e86404f2497a7"
     ]
    },
    "id": "lFi-KB1XIkVT",
    "outputId": "161ecfe9-d975-4d4c-969b-ce0ffa2e0bdb"
   },
   "execution_count": 54,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e416cf2d799d4cd692e98f804f6effed"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "while True:\n",
    "  s = input(str())\n",
    "  print(s)\n",
    "  print(dialog_manager.process_user_input(dialog_id, s))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 845
    },
    "id": "-Lpl1nH_Ityc",
    "outputId": "987134a7-b3f3-4e70-a62e-df9fcd497021"
   },
   "execution_count": 55,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "привет\n",
      "привет\n",
      "Какая температура сейчас в комнате? \n",
      "Если термостат показывает ошибку, пожалуйста, введите примерную температуру в помещении.\n",
      "23\n",
      "23\n",
      "Какая температура должна быть в комнате?\n",
      "24\n",
      "24\n",
      "Когда это произошло? Утром, днем или вечером?\n",
      "утром\n",
      "утром\n",
      "Проблема наблюдается более часа?\n",
      "да\n",
      "да\n",
      "Хотите создать заявку на техподдержку?\n",
      "да\n",
      "да\n",
      "Заявка #ticket_20250403_194916 создана.\n",
      "Текущая температура: 23.0°C\n",
      "Желаемая температура: 24.0°C\n",
      "Время возникновения: утром\n",
      "Техподдержка свяжется с вами в ближайшее время.\n",
      "спасибо\n",
      "спасибо\n",
      "Диалог завершен. Чтобы начать новую диагностику, напишите 'начать'\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-55-51968c3e33cf>\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m   \u001B[0ms\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m   \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ms\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m   \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdialog_manager\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprocess_user_input\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdialog_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0ms\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001B[0m in \u001B[0;36mraw_input\u001B[0;34m(self, prompt)\u001B[0m\n\u001B[1;32m   1175\u001B[0m                 \u001B[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1176\u001B[0m             )\n\u001B[0;32m-> 1177\u001B[0;31m         return self._input_request(\n\u001B[0m\u001B[1;32m   1178\u001B[0m             \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprompt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1179\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_parent_ident\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"shell\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001B[0m in \u001B[0;36m_input_request\u001B[0;34m(self, prompt, ident, parent, password)\u001B[0m\n\u001B[1;32m   1217\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyboardInterrupt\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1218\u001B[0m                 \u001B[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1219\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mKeyboardInterrupt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Interrupted by user\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1220\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1221\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlog\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwarning\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Invalid Message:\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexc_info\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: Interrupted by user"
     ]
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
